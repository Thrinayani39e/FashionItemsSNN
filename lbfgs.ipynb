{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"l8Lnc7SoeXdP"},"outputs":[],"source":["pip install pytorch_spiking"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"zhQ-ft_UedYm"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torchvision\n","import time\n","import pytorch_spiking\n","\n","torch.manual_seed(0)\n","np.random.seed(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JFhwrPDpefs_"},"outputs":[],"source":["train_pictures, train_labels = zip(\n","    *torchvision.datasets.FashionMNIST(\".\", train=True, download=True)\n",")\n","train_pictures = np.asarray([np.array(pic) for pic in train_pictures], dtype=np.float32)\n","train_labels = np.asarray(train_labels, dtype=np.int64)\n","test_pictures, test_labels = zip(\n","    *torchvision.datasets.FashionMNIST(\".\", train=False, download=True)\n",")\n","test_pictures = np.asarray([np.array(pic) for pic in train_pictures], dtype=np.float32)\n","test_labels = np.asarray(train_labels, dtype=np.int64)\n","\n","# normalize images so values are between 0 and 1\n","train_pictures = train_pictures / 255.0\n","test_pictures = test_pictures / 255.0\n","\n","class_labels = [\n","    \"T-shirt/top\",\n","    \"Trouser\",\n","    \"Pullover\",\n","    \"Dress\",\n","    \"Coat\",\n","    \"Sandal\",\n","    \"Shirt\",\n","    \"Sneaker\",\n","    \"Bag\",\n","    \"Ankle boot\",\n","]\n","num_classes = len(class_labels)\n","\n","plt.figure(figsize=(10, 10))\n","for i in range(25):\n","    plt.subplot(5, 5, i + 1)\n","    plt.imshow(train_pictures[i], cmap=plt.cm.binary)\n","    plt.axis(\"off\")\n","    plt.title(class_labels[train_labels[i]])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qwbcrF-tehEJ"},"outputs":[],"source":["def train(input_ssn, train_x, test_x):\n","    minibatch_size = 32\n","    optimizer = torch.optim.LBFGS(input_ssn.parameters())\n","    s = time.time()\n","    input_ssn.train()\n","\n","    # Initialize variables for early stopping\n","    patience = 5\n","    best_loss = float('inf')\n","    best_epoch = 0\n","    early_stop = False\n","\n","    for j in range(50):\n","        train_acc = 0\n","        for i in range(train_x.shape[0] // minibatch_size):\n","            input_ssn.zero_grad()\n","\n","            input_batch = train_x[i * minibatch_size : (i + 1) * minibatch_size]\n","            # flatten images\n","            input_batch = input_batch.reshape((-1,) + train_x.shape[1:-2] + (784,))\n","            batch_label = train_labels[i * minibatch_size : (i + 1) * minibatch_size]\n","            output = input_ssn(torch.tensor(input_batch))\n","\n","            # compute sparse categorical cross entropy loss\n","            logp = torch.nn.functional.log_softmax(output, dim=-1)\n","            logpy = torch.gather(logp, 1, torch.tensor(batch_label).view(-1, 1))\n","            loss = -logpy.mean()\n","\n","            loss.backward()#bptt\n","            optimizer.step()\n","\n","            train_acc += torch.mean(\n","                torch.eq(torch.argmax(output, dim=1), torch.tensor(batch_label)).float()\n","            )\n","\n","        train_acc /= i + 1\n","        print(f\"Accuracy(Training) ({j}): {train_acc.numpy()}\")\n","\n","        # Check if the loss has improved for early stopping\n","        if loss.item() \u003c best_loss:\n","            best_loss = loss.item()\n","            best_epoch = j\n","        elif j - best_epoch \u003e patience:\n","            print(\"Early stopping due to no improvement in loss.\")\n","            early_stop = True\n","            break\n","\n","    train_time= time.time() - s\n","    print(\"Training time:\",train_time)\n","\n","\n","        # compute test accuracy\n","    s1=time.time()\n","    input_ssn.eval()\n","    test_acc = 0\n","    for i in range(test_x.shape[0] // minibatch_size):\n","            input_batch = test_x[i * minibatch_size : (i + 1) * minibatch_size]\n","            input_batch = input_batch.reshape((-1,) + test_x.shape[1:-2] + (784,))\n","            batch_label = test_labels[i * minibatch_size : (i + 1) * minibatch_size]\n","            output = input_ssn(torch.tensor(input_batch))\n","\n","            test_acc += torch.mean(\n","                torch.eq(torch.argmax(output, dim=1), torch.tensor(batch_label)).float()\n","            )\n","\n","    test_acc /= i + 1\n","\n","    print(f\"Accuracy(Testing) {test_acc.numpy()}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"At7CokaPekY7"},"outputs":[],"source":["# repeat the images for n_steps\n","n_steps = 10\n","train_stream = np.tile(train_pictures[:, None], (1, n_steps, 1, 1))\n","test_stream = np.tile(test_pictures[:, None], (1, n_steps, 1, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-PS4wjSSemsQ"},"outputs":[],"source":["class SelfAttention(torch.nn.Module):\n","    def __init__(self, input_dim):\n","        super(SelfAttention, self).__init__()\n","        self.query = torch.nn.Linear(input_dim, input_dim)\n","        self.key = torch.nn.Linear(input_dim, input_dim)\n","        self.value = torch.nn.Linear(input_dim, input_dim)\n","\n","    def forward(self, x):\n","        q = self.query(x)\n","        k = self.key(x)\n","        v = self.value(x)\n","        attn_weights = torch.nn.functional.softmax(q @ k.transpose(-2, -1), dim=-1)\n","        return attn_weights @ v"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ONP4ixkeUVz"},"outputs":[],"source":["spikeaware_model = torch.nn.Sequential(\n","     torch.nn.Linear(784, 256),    #13 layers\n","     SelfAttention(256),\n","     torch.nn.SELU(),\n","    # set spiking_aware_training and a moderate dt\n","    pytorch_spiking.SpikingActivation(\n","        torch.nn.ELU(alpha=1.0), dt=0.8, spiking_aware_training=True #exponential linear unit\n","    ),\n","    torch.nn.Linear(256,128),\n","    SelfAttention(128),\n","    torch.nn.GELU(),\n","     torch.nn.Dropout(0.2),\n","       pytorch_spiking.SpikingActivation(\n","        torch.nn.ELU(alpha=1.0), dt=0.8, spiking_aware_training=True #exponential linear unit\n","    ),\n","    torch.nn.Linear(128,64),\n","    torch.nn.Dropout(0.5),\n","    pytorch_spiking.TemporalAvgPool(),\n","    torch.nn.Linear(64, 10),\n",")\n","train(spikeaware_model, train_stream, test_stream)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOWD0PKXSTrrVJAgFDBEPGU","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}